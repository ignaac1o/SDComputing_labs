{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOLO AÃ‘ADIR COSAS DEBAJO DEL CHUNK DE CADA NOMBRE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESTA PARTE ES PARA JAVIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESTA PARTE ES PARA ALMODOVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESTA PARTE ES PARA ALBERTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
      "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
      "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
      "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
      "       'total_amount'],\n",
      "      dtype='object')\n",
      "15.577018712603214 No taxes mean\n",
      "16.078110822888735 Total amount mean\n",
      "0.4972142408420099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "payment_type\n",
       "1    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "2    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "3    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "4    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: mta_tax, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD4CAYAAAAQP7oXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfcklEQVR4nO3de5ScdZ3n8fenqjr3QBLSuXAJQQwIOhCgxduisCwDsrM67s7Mwngb1xn0oLsz65w9Kjs7urPr0XVH3dkzow4qiqyirnjBPXhBhoseRGkk3O8xkEBImtwvnXRXPd/9o57qrm46SaXzVFX3z8/rnDpV9avnqfrlSVd96nd5fqWIwMzMrBWlblfAzMymD4eGmZm1zKFhZmYtc2iYmVnLHBpmZtaySrcrcCQWL14cK1eu7HY1zMymlXvuueeFiOidzL7TOjRWrlxJf39/t6thZjatSHp6svu6e8rMzFrm0DAzs5Y5NMzMrGUODTMza5lDw8zMWta20JB0jaTNkh5sKvumpDX5ZZ2kNXn5SkmDTY99vl31MjOzyWvnlNuvAH8PfLVREBH/tnFb0qeAHU3bPxURq9tYHzMzO0Jta2lExB3A1okekyTgj4Dr2/X6Zl0TAfd+Dar7u10Ts8J1a0zjPGBTRDzRVHaSpHsl3S7pvAPtKOkKSf2S+gcGBtpfU7PD9ej/g+9fCbd9vNs1MStct0Ljcsa2MjYCKyLiLOADwNclHTXRjhFxdUT0RURfb++kzoI3a699O+vXu57vbj3M2qDjoSGpAvxr4JuNsojYHxFb8tv3AE8Bp3S6bmaFKJXr15F1tx5mbdCNlsa/AB6NiA2NAkm9ksr57ZcAq4C1Xaib2ZFT/rbKat2th1kbtHPK7fXAL4BTJW2Q9O78oct48QD464H7Jd0HfBt4b0RMOIhuNuU1QiMcGpaetk25jYjLD1D+JxOU3QDc0K66mHVUo3vKLQ1LkM8INyvaSEvDYxqWHoeGWdHkgXBLl0PDrGjunrKEOTTMiubuKUuYQ8OsaCPdU25pWHocGmbt4u4pS5BDw6xgQ9UqALv2DXW5JmbFc2iYFWzD1j0APD2wq8s1MSueQ8OsYBVF/YbHNCxBDg2zgvWUGqHh2VOWHoeGWcEiDws5NCxBDg2zgmVZIzTcPWXpcWiYFSyrNcIiuloPs3ZwaJgVrNHSKLmlYQlyaJgVLMtP6vOYhqXIoWFWsJGWhrunLEEODbOCRd7SKOOWhqXHoWFWsEZLoyyHhqXHoWFWsMaYhrunLEVtCw1J10jaLOnBprKPSnpW0pr8cmnTYx+W9KSkxyRd3K56mbVbjIxpuKVh6WlnS+MrwCUTlH8mIlbnl5sAJJ0OXAa8PN/ns1LjRwnMppeR7imHhiWobaEREXcAW1vc/M3ANyJif0T8BngSOLdddTNrp/DsKUtYN8Y03i/p/rz7amFedhywvmmbDXmZ2bQT0RjTcEvD0tPp0PgccDKwGtgIfCov1wTbTvg1TdIVkvol9Q8MDLSlkmZHwlNuLWUdDY2I2BQRtagvA/oFRrugNgAnNG16PPDcAZ7j6ojoi4i+3t7e9lbYbBIyD4RbwjoaGpKWN919C9CYWXUjcJmkmZJOAlYBv+pk3cyK4tlTlrJKu55Y0vXA+cBiSRuAjwDnS1pNvetpHfAegIh4SNK3gIeBKvC+CK/2ZtNT+OQ+S1jbQiMiLp+g+EsH2f5jwMfaVR+zTmn8CJNbGpYinxFuVrDwGeGWMIeGWcE8pmEpc2iYFS3vnqo4NCxBDg2zgkW4W8rS5dAwK5on/lnCHBpmBfPPvFrKHBpmBRvTPeWuKkuMQ8OscE0tDYeGJcahYVa0Md1TDg1Li0PDrGBjxjQ8vmGJcWiYFc2hYQlzaJgVLTymYelyaJgVzS0NS5hDw6xoY6bcOjQsLQ4Ns6J59pQlzKFhVrSm0MhqXlLE0uLQMCtY85Tbxu+Fm6XCoWFWtKbQqHlMwxLj0DAr3Og4RrilYYlxaJgVrLl7quYxDUtM20JD0jWSNkt6sKnsf0p6VNL9kr4raUFevlLSoKQ1+eXz7aqXWds1hUa4e8oS086WxleAS8aV3Qy8IiLOAB4HPtz02FMRsTq/vLeN9TJrqzED4TWHhqWlbaEREXcAW8eV/SQiqvndu4Dj2/X6Zt3TNKbhloYlpptjGv8O+GHT/ZMk3SvpdknnHWgnSVdI6pfUPzAw0P5amh2u5paG156yxHQlNCT9Z6AKfC0v2gisiIizgA8AX5d01ET7RsTVEdEXEX29vb2dqbDZYWjunorMA+GWlo6HhqR3Ar8HvDXy38WMiP0RsSW/fQ/wFHBKp+tmVozR1kXm0LDEdDQ0JF0CfBB4U0TsbSrvlVTOb78EWAWs7WTdzIoypqXh7ilLTKVdTyzpeuB8YLGkDcBHqM+WmgncLAngrnym1OuBv5FUBWrAeyNi64RPbDbVjeme8kC4paVtoRERl09Q/KUDbHsDcEO76mLWSRrTPeXQsLT4jHCzgsktDUuYQ8OsaA4NS5hDw6xgwsuIWLocGmYFU3hMw9Ll0DArmhcstIQ5NMwKNqZ7yi0NS4xDw6xgzd1TPrnPUuPQMCvY2JaGlxGxtDg0zAo2ZiA8HBqWFoeGWeGaxjHcO2WJcWiYFay5e8qr3FpqHBpmBWvunsKzpywxDg2zgomMLAR49pSlx6FhVjBFUMvfWplP7rPEODTMCiYyssZby2MalhiHhlnBRFDN31runrLUODTMCqbIqFEGvPaUpcehYVYwESPdUz4j3FLj0DArmCKjpkZLo8uVMStY20JD0jWSNkt6sKlskaSbJT2RXy9seuzDkp6U9Jiki9tVL7N2E9HUPeWWhqWlpdCQdIOkfynpcELmK8Al48o+BNwSEauAW/L7SDoduAx4eb7PZ6X8q5rZNFNqmj3lpdEtNa2GwOeAPwaekPQJSS871A4RcQewdVzxm4Fr89vXAr/fVP6NiNgfEb8BngTObbFuZlPOaPeU+6csLS2FRkT8NCLeCpwNrANulnSnpHdJ6jmM11saERvz59wILMnLjwPWN223IS97EUlXSOqX1D8wMHAYL23WGYqMLO+ewt1TlpiWu5skHQP8CfCnwL3A31EPkZsLqIcmKJvwK1pEXB0RfRHR19vbW8BLmxVr7OwptzQsLZVWNpL0HeBlwHXAv2q0FoBvSuo/jNfbJGl5RGyUtBzYnJdvAE5o2u544LnDeF6zKaNERqYyhM/TsPS02tL4YkScHhEfbwSGpJkAEdF3GK93I/DO/PY7ge83lV8maaakk4BVwK8O43nNpgwRo2MabmlYYloNjf8+QdkvDraDpOvzbU6VtEHSu4FPABdJegK4KL9PRDwEfAt4GPgR8L7wXEWbphQZ0Xhr+c/YEnPQ7ilJy6gPSM+WdBajYw9HAXMOtm9EXH6Ahy48wPYfAz520NqaTQMlot49hWdPWXoONaZxMfXB7+OBTzeV7wKualOdzKY1NcY08JiGpeegoRER1wLXSvo3EXFDh+pkNq2JIEbGNBwalpZDdU+9LSL+D7BS0gfGPx4Rn55gN7Pfas3dU158ylJzqO6pufn1vHZXxCwVY7unPBBuaTlU99Q/5tf/tTPVMZv+SgQjExPd0rDEtLpg4SclHSWpR9Itkl6Q9LZ2V85sOhIZWan+fcwD4ZaaVs/T+N2I2An8HvWzt08B/lPbamU2jZVidCDcLQ1LTauh0ViU8FLg+ogYv3qtmeWaZ0/hX+6zxLS09hTwA0mPAoPAlZJ6gX3tq5bZ9FUiA/9ynyWq1aXRPwS8BuiLiGFgD/XfwDCzcUrEyJiGlxGx1LTa0gA4jfr5Gs37fLXg+phNeyKg8SOXHgi3xLS6NPp1wMnAGqDx1SlwaJi9SImMGJk95f4pS0urLY0+4PTwO8DskMqKpjENtzQsLa3OnnoQWNbOipilYGStqVJjyq1Dw9LSaktjMfCwpF8B+xuFEfGmttTKbJrKsvqvg0dj6M+Nc0tMq6Hx0XZWwiwVWVajDFD2GeGWppZCIyJul3QisCoifippDlBub9XMpp8sP5lPnj1liWp17ak/A74N/GNedBzwvTbVyWzaaoxpePaUparVgfD3Aa8DdgJExBPAknZVymy6arQ0yENDbmlYYlod09gfEUNS/SfC8xP8JvUVStKpwDebil4C/DWwAPgzYCAvvyoibprMa5h1S5a3NFTylFtLU6uhcbukq4DZki4CrgR+MJkXjIjHgNUAksrAs8B3gXcBn4mIv53M85pNBdnIlFvPnrI0tdo99SHqLYAHgPcANwF/VcDrXwg8FRFPF/BcZl0XLwoNtzQsLa3OnsokfQ/4XkQMHGr7w3AZcH3T/fdLegfQD/xlRGwbv4OkK4ArAFasWFFgVcyO3MiYhmdPWaIO2tJQ3UclvQA8CjwmaUDSXx/pC0uaAbwJ+L950eeor2+1GtgIfGqi/SLi6ojoi4i+3t7eI62GWaHGD4R79pSl5lDdU39BfdbUKyPimIhYBLwKeJ2k/3iEr/1G4NcRsQkgIjZFRC3qI4dfAM49wuc367hGaIS7pyxRhwqNdwCXR8RvGgURsRZ4W/7Ykbicpq4pScubHnsL9fWuzKaXLG9Z+OdeLVGHGtPoiYgXxhdGxICknol2aEV+RvlF1AfVGz4paTX1qbzrxj1mNi1k+Y8uqdT4PuaWhqXlUKExNMnHDioi9gLHjCt7+2Sfz2yqGJk9pTJZCLmlYYk5VGicKWnnBOUCZrWhPmbTWlZrDISX6me/ekzDEnPQ0IgIL0podhhiZEyjREbJs6csOa2e3GdmLWge0wjJLQ1LjkPDrEDRtDR6IC9YaMlxaJgVaMxAOCImt66n2ZTl0DArUGNVW5VKBCV3T1lyHBpmBcrGdE/hKbeWHIeGWYFGu6fc0rA0OTTMChTZaPdUhvAZ4ZYah4ZZgUZCQyVAXnvKkuPQMCvQyM+7NloaDg1LjEPDrEBjB8I9pmHpcWiYFShGzggv12dPeUzDEuPQMCtQY+0pqUSo5N4pS45Dw6xAI8uIlLyMiKXJoWFWoLHnacjdU5Ych4ZZkfKWRSlvaXhpdEuNQ8OsQM0n9wUld09ZchwaZgUaWbBQ+e9peJVbS8yhfu61LSStA3YBNaAaEX2SFgHfBFYC64A/ioht3aif2WQ1ztOgVM4Hwh0alpZutjQuiIjVEdGX3/8QcEtErAJuye+bTS+NMY385D5R63KFzIo1lbqn3gxcm9++Fvj97lXFbHJGxzTKhNzSsPR0KzQC+ImkeyRdkZctjYiNAPn1kol2lHSFpH5J/QMDAx2qrllrmn+EqUYZhVsalpaujGkAr4uI5yQtAW6W9GirO0bE1cDVAH19ff4aZ1NK8yq3GSVKDg1LTFdaGhHxXH69GfgucC6wSdJygPx6czfqZnZEGi2NcolMZU+5teR0PDQkzZU0v3Eb+F3gQeBG4J35Zu8Evt/pupkdqdGWRpmQB8ItPd3onloKfFdS4/W/HhE/knQ38C1J7waeAf6wC3UzOzIjZ4SLYSrunrLkdDw0ImItcOYE5VuACztdH7MiNZZGR2UyeUzD0jOVptyaTXuN2VPlUtljGpYkh4ZZgcasPaUyJY9pWGIcGmZFagqNTGV3T1lyHBpmRYrmM8Ld0rD0ODTMChRNs6dCJUoe07DEODTMitTU0shUcUvDkuPQMCvQ2N/TcEvD0uPQMCtS1uieqo9plN3SsMQ4NMwKFM2/Ea6yWxqWHIeGWZFibEvDYxqWGoeGWYFGTu4rN07uc0vD0uLQMCvQyLIhKkHJYxqWHoeGWYGyPDQqpUo+EO6WhqXFoWFWpMaChXn3VNnLiFhiHBpmBcpqeUujXAa3NCxBDg2zIuUti1K5TJQqHgi35Dg0zAqUZaMD4aEyFQ+EW2IcGmZFGjd7yi0NS41Dw6xA0dTSQGUqykbLzBLg0DArUDS1NKJUBpq6rMwS0PHQkHSCpFslPSLpIUl/npd/VNKzktbkl0s7XTezIxWNKbYqIdVDo1Yd7mKNzIpV6cJrVoG/jIhfS5oP3CPp5vyxz0TE33ahTmbFGOmeElGq5EXVLlbIrFgdD42I2AhszG/vkvQIcFyn62HWDpFl1ChRBshDwy0NS0lXxzQkrQTOAn6ZF71f0v2SrpG08AD7XCGpX1L/wMBAp6pq1pKIjED1O/mYRi3ztFtLR9dCQ9I84AbgLyJiJ/A54GRgNfWWyKcm2i8iro6Ivojo6+3t7VR1zVoTGVkeGspDI9zSsIR0JTQk9VAPjK9FxHcAImJTRNSiPv3kC8C53aib2ZFQViPL31Yq10NjuOoxDUtHN2ZPCfgS8EhEfLqpfHnTZm8BHux03cyOVCmGGKanfrtcv64Ou6Vh6ejG7KnXAW8HHpC0Ji+7Crhc0moggHXAe7pQN7MjUs6GGNYMADQyEO6WhqWjG7Onfg6NkcIxbup0XcyKVsmGGFajpVF/e1VrbmlYOnxGuFmBmlsa5XxMo+qWhiXEoWFWoEoMUW20NCr168yzpywhDg2zApVjmGre0ih59pQlyKFhVqCerKmlUWq0NBwalg6HhlmBKjHMcCkf06jkZ4R7INwS4tAwK1AlhshKje6pekvDa09ZShwaZgWqxBC10sz67ZEpt157ytLh0DArUE8MEeW8pZHPnvLaU5YSh4ZZgSoxTFautzTKlfyMcK9yawlxaJgVaAbDkLc0Ko3Q8NpTlhCHhlmBemKYKM8CRgfC/ct9lhKHhllBIoKZDBOVekujp8er3Fp6urHKrVmSdgzuZF8F1pf3M2/LQ9SGnmdbT4UdQzuJCOq/CmA2vSkiul2HSevr64v+/v5uV8N+y2SRsXb7WtYMrOGBFx5g7fa1rNu5ju37tx9wnxmlGSyft5xVC1ZxysJTeMXiV3DWkrOYN2Ne5ypulpN0T0T0TWZftzTMWrBt3zZ+9uzPuG39bdy18S52De0CYOHMhZy84GQuXHEhi0oLOO7nn2Tz8jdx2usvoza0h/3f+VN+segNLDzzXDbs3sAT257glmduIQhKKnH6otN55fJXcv7x53Nm75mU85+INZuqHBpmB7BuxzpuW38bt66/lTUDa8giY8nsJVx04kWcveRsVi9ZzYr5K0a6nZ5d/xuO2/0R7pn1Us454XyIYN+eKnNnL+ANfR8Yed69w3t54IUHuPv5u+nf1M91D1/Hlx/8MgtnLuS848/jghMu4LXHvpY5PXO68w83Owh3T5nlqlmV+wbu4/b1t3Pr+ltZt3Md5VrQVzmZN8z6Hc4urWTZ7h5qW7eS7d1LtmfPmOvB7duYufVx9s1ezqz5iyAyqpseZ3/PXOaveBmaNZPSzFlo1ixK8+ZSWbCA0tFHU503m8drz/HrfU/w870P8Mys3VRn9XDusa/iguMv4A0nvIFlc5d1+/BYQtw9ZTYJ2Z49bF3/JPc9fCtPPvFLBp5+jLnb99G7W3xg3xyO2TWLnu17IB4HHgdgM0C5TGnu3PplzpyR6+pRRzFvX43hxQvpWXICUomhfWtRgGbOJPbtZ3jHDmLffrLdu6lt304MDQHQC1ycXwCqM8XW+Xeyee4dfH8eaMlilp54GqtOeTUrX3oOPcuWUVm8GJU8AdI6y6FhyYkIatu2Ud20ieFNm6g+v4nq5k0MP7+Jfc8/y55nnyEGttCzt/6BfWx+AajNm8OsZcuZceKxVJYuoWfpsvx6KZVly6gsWUJ5wYIJZ0Ldevst/M6tP+T5N76dZa/6QwAe+Pj59NT2ceJffXnCesbgILUdO6ht305t+3aqL2yhunkT1c2bWbhpE0ufW8/g889SefQFKrU7gDt4urF/uYSWLGb28uPpWbaUyrLl9euly/L7ebCUPU5ixZlyoSHpEuDvgDLwxYj4RJerZFNEtm9f/QN2yxaqAwMvvmwevR3jzo3IBLvnV9g8t8aW+bD9tBKVZceybOXLedkpr+Glp7yaGcuWUZo9e9L1q259BoA5C5aOlNVmLeKoHQ9PuL0kNGcOpTlz6Fm+/KDPHRFs2biW/gd+zOOP3cULzzzGrC27WLRrgKXbtrF0/SMctX2I8vC4JUvKZSpLRkOvZ+lSKsuX1VsqS5ZSXriA8oIFlI86yuFiLZlSoSGpDPwDcBGwAbhb0o0RMeG77vmBZ7ju9q9x2qmnkkVGLWoEQUUVyqUyZZWplCqUVR6537h9oG0a5SW52X+4olYjhoeJarX+oV2tjtyuX1eJoSGywb1ke/cSg4NkewfJBgfrYwODe4m9g9R276K2YwfZ9h3UduygumMH2Y4dxP79E75udd4s9i+Yw+6jZ7DteNi0aj7rZ+1h05xhtswXW+dDz+JeXrr4VM7oPYNzlp7DGb1nMLsy+YCYyOwNP2eQGcw76dyRMs05hgXbd7BrcIj5s2dM+rklsfjYk7nk2Cu55OIriQie3vk0/Zv66d98L49tfYyntj3JrL1wzK76ZeX++awYnMvSPWWO3rGZufc/w8wtuyjtn+BkQ4nS/PmjIbJgAeWjjx7tgpszh9Kcpttz8+tZs6CnB41cZtSvZ+S3Z/SgSsXdaAmZUgPhkl4DfDQiLs7vfxggIj4+0fanz5kd1710Jc0dBZrgn9MoG9OhMEHZRPuO2UVjb0fTE8QBtjlg2fh98+c74LZN24xcH+A1Gv8W5TuPuW66Pea4NG33orLmbZuOkQJKAaUMyrUjX14gA4Z6YHAm7J4Fe2bDrlmwa7bYPRt2z6pf75wD2+aK7fNg+zwYrtRrOa8WLK7B0iosHYal1WDFMJw0BEdnR1i5FqyMDTw8+xxO/+A/jZQ9/ZN/4MQ7r+JZlpCVeur/x5Rox7tuGFjfA+tmwKYKPJ9fNldgexmqEkQwdx8s2gWLdgXzB2H+IMwbrN8+ahDmDwbzBmHePpg1BDOHYcYRroRSK9VbezH+Qutl6OCvQQvbtHLcx7+XJqOI52inC+58NJmB8OOA9U33NwCvat5A0hXAFQAnL5zPzrOOg327ERkiIJr+8GjcDrL8dsboH2BGEOR/zNS3a95m5EM8yB9l3F/duLJofjiIOEAojfsArz82uudEH+LN+4/54J7g+cYHyZiAmiComkMIaewf/JjHmv7lI88nshJkZYiSqJUgylAriSiNPpY13a72iOGKqPbUL7UeMdwjskr99dX0cj1RYkaIHsS8EItCzEDMjBLzshLzdpWZn5WZGyXKE31iVCCrwLYXP1K4LZUzWPnG/zCm7MSLruSerVvhuXvJsowSgWhfgi0AVgf1BGlqUATBPgU7VWNXqcaemRlDM4P9CvYrY7+CbQo2KUbeLxlBrfF+yDLKw1CuZlSGgp5h6BkOeoaDUgalGpRrQTmDUi3qXyKyvKxW/1KhiLFfZqLxtxwjt5W/8RpfapovPSUd2Vn1LXxBPuSzt5A6RTzHVDbVQmOi4z32YzriauBqqE+5veDan3aiXmaTI3HOZf+l27UwG+sIwneqdTRuAE5oun888FyX6mJmZuNMtdC4G1gl6SRJM4DLgBu7XCczM8tNqe6piKhKej/wY+pTbq+JiIe6XC0zM8tNqdAAiIibgJu6XQ8zM3uxqdY9ZWZmU5hDw8zMWubQMDOzljk0zMysZVNqGZHDJWkX8Fi36zFFLAZe6HYlpggfi1E+FqN8LEadGhHzJ7PjlJs9dZgem+z6KamR1O9jUedjMcrHYpSPxShJk/71OndPmZlZyxwaZmbWsukeGld3uwJTiI/FKB+LUT4Wo3wsRk36WEzrgXAzM+us6d7SMDOzDnJomJlZy6ZFaEi6RNJjkp6U9KEJHpek/50/fr+ks7tRz05o4Vi8NT8G90u6U9KZ3ahnJxzqWDRt90pJNUl/0Mn6dVIrx0LS+ZLWSHpI0u2drmOntPAeOVrSDyTdlx+Ld3Wjnu0m6RpJmyU9eIDHJ/e5GRFT+kJ9ifSngJcAM4D7gNPHbXMp8EPqv/z3auCX3a53F4/Fa4GF+e03/jYfi6bt/on6ysl/0O16d/HvYgHwMLAiv7+k2/Xu4rG4Cvgf+e1eYCswo9t1b8OxeD1wNvDgAR6f1OfmdGhpnAs8GRFrI2II+Abw5nHbvBn4atTdBSyQtLzTFe2AQx6LiLgzIho/iX0X9V8/TFErfxcA/x64Adjcycp1WCvH4o+B70TEMwARkerxaOVYBDBf9R8cn0c9NKqdrWb7RcQd1P9tBzKpz83pEBrHAeub7m/Iyw53mxQc7r/z3dS/SaTokMdC0nHAW4DPd7Be3dDK38UpwEJJt0m6R9I7Ola7zmrlWPw9cBr1n5J+APjziMg6U70pZVKfm9NhGZGJfgF9/DzhVrZJQcv/TkkXUA+Nf9bWGnVPK8fifwEfjIha/Utlslo5FhXgHOBCYDbwC0l3RcTj7a5ch7VyLC4G1gD/HDgZuFnSzyJiZ5vrNtVM6nNzOoTGBuCEpvvHU/+GcLjbpKClf6ekM4AvAm+MiC0dqluntXIs+oBv5IGxGLhUUjUivteRGnZOq++RFyJiD7BH0h3AmUBqodHKsXgX8Imod+w/Kek3wMuAX3WmilPGpD43p0P31N3AKkknSZoBXAbcOG6bG4F35LMBXg3siIiNna5oBxzyWEhaAXwHeHuC3yKbHfJYRMRJEbEyIlYC3wauTDAwoLX3yPeB8yRVJM0BXgU80uF6dkIrx+IZ6i0uJC0FTgXWdrSWU8OkPjenfEsjIqqS3g/8mPrMiGsi4iFJ780f/zz1mTGXAk8Ce6l/k0hOi8fir4FjgM/m37CrkeDKni0ei98KrRyLiHhE0o+A+4EM+GJETDgVczpr8e/ivwFfkfQA9S6aD0ZEckumS7oeOB9YLGkD8BGgB47sc9PLiJiZWcumQ/eUmZlNEQ4NMzNrmUPDzMxa5tAwM7OWOTTMzKxlDg0zM2uZQ8PMzFr2/wH1EglFZNFJAwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2 - Average total price per trip excluding taxes\n",
    "\n",
    "import pandas as pd\n",
    "data=pd.read_csv(\"C:/Users/Alberto/Desktop/MÃ¡ster UC3M/3rd quarter/ComputaciÃ³n Escalada/SDComputing_labs/LAB2/tripdata_2017-01.csv\",header=0)\n",
    "print (data.columns)\n",
    "\n",
    "#We select the columns corresponding to the fare, tip, tolls and extra amount and the improvement surcharge, excluding the taxes and we add them together.\n",
    "\n",
    "no_taxes = data['fare_amount'] + data['tip_amount'] + data['tolls_amount'] + data['extra'] + data['improvement_surcharge']\n",
    "\n",
    "#Now, we compute the mean of this quantity. \n",
    "meanprice=no_taxes.mean()\n",
    "print (meanprice, 'No taxes mean')\n",
    "\n",
    "#Let's compare this mean value to the mean of the total amount given to the driver.\n",
    "\n",
    "total = data['total_amount']\n",
    "total_mean = total.mean()\n",
    "print (total_mean, 'Total amount mean')\n",
    "\n",
    "#We can see that there is a difference of close to 0.5$ between these amounts, meaning that the fraction of the total amount spent in taxes\n",
    "#is close to 0.5$ for every trip. Let's check this fact: \n",
    "print(data['mta_tax'].mean())\n",
    "\n",
    "#We can check how the amount paid in taxes varies in terms of the \n",
    "snd_analysis = data.loc[:,['payment_type', 'mta_tax', 'total_amount']]\n",
    "snd_analysis.groupby([\"payment_type\"])[\"mta_tax\"].plot(kind='density',xlim=[0,1],xlabel=\"Price\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5) (DESKTOP-25CIBG5 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 14 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 14 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1764/1758808597.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrdd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_taxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1222\u001b[0m         \u001b[1;36m6.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m         \"\"\"\n\u001b[1;32m-> 1224\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36mfold\u001b[1;34m(self, zeroValue, op)\u001b[0m\n\u001b[0;32m   1076\u001b[0m         \u001b[1;31m# zeroValue provided to each partition is unique from the one provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m         \u001b[1;31m# to the final reduce call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1078\u001b[1;33m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1079\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    947\u001b[0m         \"\"\"\n\u001b[0;32m    948\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m             \u001b[0msock_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    950\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1309\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1310\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 0.0 failed 1 times, most recent failure: Lost task 5.0 in stage 0.0 (TID 5) (DESKTOP-25CIBG5 executor driver): org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 14 more\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2258)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2207)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2206)\r\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\r\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2206)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1079)\r\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1079)\r\n\tat scala.Option.foreach(Option.scala:407)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1079)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2445)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2387)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2376)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2196)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2217)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2236)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2261)\r\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\r\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\r\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: org.apache.spark.SparkException: Python worker failed to connect back.\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:182)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:107)\r\n\tat org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:119)\r\n\tat org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:145)\r\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:65)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\nCaused by: java.net.SocketTimeoutException: Accept timed out\r\n\tat java.net.DualStackPlainSocketImpl.waitForNewConnection(Native Method)\r\n\tat java.net.DualStackPlainSocketImpl.socketAccept(Unknown Source)\r\n\tat java.net.AbstractPlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.PlainSocketImpl.accept(Unknown Source)\r\n\tat java.net.ServerSocket.implAccept(Unknown Source)\r\n\tat java.net.ServerSocket.accept(Unknown Source)\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:174)\r\n\t... 14 more\r\n"
     ]
    }
   ],
   "source": [
    "#Now, let's implement the previous computations with pyspark. \n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"prueba\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(no_taxes)\n",
    "from pyspark.sql.functions import mean as _mean \n",
    "totalsum rdd.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "348d93889cdc789e6cbe038b88f22de38d4107789a7ffcd22b7fa3c799b7a993"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
