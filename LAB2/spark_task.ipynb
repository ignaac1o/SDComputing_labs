{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOLO AÑADIR COSAS DEBAJO DEL CHUNK DE CADA NOMBRE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESTA PARTE ES PARA JAVIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESTA PARTE ES PARA ALMODOVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESTA PARTE ES PARA ALBERTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
      "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
      "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
      "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
      "       'total_amount'],\n",
      "      dtype='object')\n",
      "15.353715345033166 No taxes mean\n",
      "15.854891789885082 Total amount mean\n",
      "0.4974637874404095\n",
      "5.099730730056763\n"
     ]
    }
   ],
   "source": [
    "# 2 - Average total price per trip excluding taxes\n",
    "import pandas as pd\n",
    "import time\n",
    "start = time.time()\n",
    "data1=pd.read_csv(\"C:/Users/Alberto/Desktop/Máster UC3M/3rd quarter/Computación Escalada/SDComputing_labs/LAB2/tripdata_2017-01.csv\",header=0)\n",
    "data2=pd.read_csv(\"C:/Users/Alberto/Desktop/Máster UC3M/3rd quarter/Computación Escalada/SDComputing_labs/LAB2/tripdata_2017-02.csv\", header=0)\n",
    "data = pd.concat([data1,data2])\n",
    "print (data.columns)\n",
    "\n",
    "#We select the columns corresponding to the fare, tip, tolls and extra amount and the improvement surcharge, excluding the taxes and we add them together.\n",
    "\n",
    "no_taxes = data['fare_amount'] + data['tip_amount'] + data['tolls_amount'] + data['extra'] + data['improvement_surcharge']\n",
    "\n",
    "#Now, we compute the mean of this quantity. \n",
    "meanprice=no_taxes.mean()\n",
    "print (meanprice, 'No taxes mean')\n",
    "\n",
    "#Let's compare this mean value to the mean of the total amount given to the driver.\n",
    "\n",
    "total = data['total_amount']\n",
    "total_mean = total.mean()\n",
    "print (total_mean, 'Total amount mean')\n",
    "\n",
    "#We can see that there is a difference of close to 0.5$ between these amounts, meaning that the fraction of the total amount spent in taxes\n",
    "#is close to 0.5$ for every trip. Let's check this fact: \n",
    "print(data['mta_tax'].mean())\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print (end-start)\n",
    "#We can check how the amount paid in taxes varies in terms of the \n",
    "#snd_analysis = data.loc[:,['payment_type', 'mta_tax', 'total_amount']]\n",
    "#snd_analysis.groupby([\"payment_type\"])[\"mta_tax\"].plot(kind='density',xlim=[0,1],xlabel=\"Price\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'findspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10352/3970536109.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#!pip install pyspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'findspark'"
     ]
    }
   ],
   "source": [
    "#!pip install pyspark\n",
    "import findspark \n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd \n",
    "spark = SparkSession.builder.appName(\"prueba\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "data_spark = spark.read.option(\"header\",\"true\").csv(\"DATA/*.csv\")\n",
    "\n",
    "#Now, we select the columns corresponding to the amount of money excluding the taxes. \n",
    "no_taxes_rdd = data_spark.select(['fare_amount', 'tip_amount', 'tolls_amount', 'extra', 'improvement_surcharge'])\n",
    "\n",
    "#Since we want to compute the mean value, we need to compute the sum of all the elements of the object, the count of these elements \n",
    "#and divide them. \n",
    "#Let's start by computing and printing the number of observations present in the rdd object. \n",
    "count = no_taxes_rdd.count()\n",
    "print(count)\n",
    "#Secondly, we sum the elements of the rdd thanks to the function .reduce(), which allows us to make computations between the elements\n",
    "#of a list. \n",
    "suma = no_taxes_rdd.reduce(lambda a,b : (a+b))\n",
    "print(suma)\n",
    "#Lastly, we divide them and obtain the mean value. \n",
    "print(suma/count)\n",
    "\n",
    "#We can do the same thing for the 'mta_tax' value. \n",
    "\n",
    "taxes = data_spark.select(['mta_tax'])\n",
    "count2 = taxes.count()\n",
    "suma2 = taxes.reduce(lambda a,b : a+b)\n",
    "\n",
    "mean = suma2/count2\n",
    "print(mean)\n",
    "\n",
    "#We have obtained the same results as we did in the python version, obtaining a mean value for the taxes amount close to 0.5$. \n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "348d93889cdc789e6cbe038b88f22de38d4107789a7ffcd22b7fa3c799b7a993"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
