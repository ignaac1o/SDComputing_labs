{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UuKnoLmH-9_",
        "outputId": "233f1c21-ee7f-4de5-922f-7016e1bb04cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1942420, 17)\n",
            "[11  0  6  7 19  8  9 10 12 13 14 15 16 17  1  2  3  4  5 18 20 21 22 23]\n",
            "E    631164\n",
            "A    566760\n",
            "M    473142\n",
            "N    271354\n",
            "Name: tpep_pickup_hour_slots, dtype: int64\n",
            "6.89449405670166\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:title={'center':'Barplot'}>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1008x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib as plt\n",
        "\n",
        "# Read both datasets and concatenate. \n",
        "start = time.time()\n",
        "data1 = pd.read_csv(\"tripdata_2017-01.csv\")\n",
        "data2 = pd.read_csv(\"tripdata_2017-02.csv\")\n",
        "data = pd.concat([data1,data2])\n",
        "print(data.shape)\n",
        "\n",
        "# Change the format of variable to datetime and extract the hour\n",
        "data['tpep_pickup_datetime'] = data['tpep_pickup_datetime'].astype('datetime64[ns]') \n",
        "data['tpep_pickup_hour'] = data.tpep_pickup_datetime.dt.hour\n",
        "\n",
        "# Print unique values\n",
        "print(data['tpep_pickup_hour'].unique())\n",
        "\n",
        "# Convert the discrete variable to continuous variable\n",
        "col         = 'tpep_pickup_hour'\n",
        "conditions  = [ (data[col] >= 0) & (data[col] < 6), \n",
        "                (data[col]>= 6) & (data[col] < 12), \n",
        "               (data[col]>= 12) & (data[col] < 18),\n",
        "               (data[col]>= 18) & (data[col] <= 24) \n",
        "  ]\n",
        "choices     = [ 'N', 'M', 'A', 'E']\n",
        "    \n",
        "data[\"tpep_pickup_hour_slots\"] = np.select(conditions, choices, default=np.nan)\n",
        "\n",
        "# Now there are only four categories which express the time zone\n",
        "data['tpep_pickup_hour_slots'].unique()\n",
        "\n",
        "# Relative frequencies\n",
        "print(data['tpep_pickup_hour_slots'].value_counts())\n",
        "end = time.time()\n",
        "print(end-start)\n",
        "\n",
        "# Barlot of the new variable created\n",
        "data['tpep_pickup_hour_slots'].value_counts().plot(kind='bar',\n",
        "                                    figsize=(14,8),\n",
        "                                    title=\"Barplot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7NYs3Q5gxLL",
        "outputId": "74ff7c2b-a1e5-4828-de50-66ac1c954745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1942420, 17)\n",
            "+----------+------+\n",
            "|slots_hour| count|\n",
            "+----------+------+\n",
            "|         E|631164|\n",
            "|         M|473142|\n",
            "|         A|566760|\n",
            "|         N|271354|\n",
            "+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import libraries \n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import IntegerType\n",
        "import time\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Create a Spark session. The number of cores selected will be crutial.\n",
        "spark = SparkSession.builder\\\n",
        "      .master(\"local[6]\")\\\n",
        "      .appName(\"Study2\")\\\n",
        "      .getOrCreate()\n",
        "\n",
        "start = time.time()\n",
        "data_sp1 = spark.read.csv('tripdata_2017-01.csv', header = True)\n",
        "data_sp2 = spark.read.csv('tripdata_2017-02.csv', header = True)\n",
        "data_sp = data_sp1.union(data_sp2)\n",
        "print((data_sp.count(), len(data_sp.columns)))\n",
        "\n",
        "\n",
        "data_sp = data_sp.withColumn(\"tpep_pickup_timestap\",to_timestamp(\"tpep_pickup_datetime\")) \n",
        "data_sp = data_sp.withColumn(\"hour\", hour(to_timestamp(\"tpep_pickup_timestap\",\"yyyy-MM-dd HH:mm:ss\")))\n",
        "data_sp = data_sp.withColumn(\"slots_hour\", when((col(\"hour\") >= 0) & (col(\"hour\") < 6),\"N\")\n",
        "                                 .when((col(\"hour\") >= 6) & (col(\"hour\") < 12),\"M\")\n",
        "                                 .when((col(\"hour\") >= 12) & (col(\"hour\") < 18),\"A\")\n",
        "                                 .when((col(\"hour\") >= 18) & (col(\"hour\") <= 24),\"E\")\n",
        "                                 .when(col(\"hour\").isNull() ,\"\"))\n",
        "                            \n",
        "data_sp.groupBy('slots_hour').count().show()\n",
        "data_sp = data_sp.withColumn(\"slots_hour\", data_sp[\"slots_hour\"].cast(IntegerType()))\n",
        "#data = data_sp.toPandas()\n",
        "spark.stop()\n",
        "# Barlot of the new variable created\n",
        "#data_sp['slots_hour'].value_counts().plot(kind='bar',\n",
        "                                    #figsize=(14,8),\n",
        "                                    #title=\"Barplot\")\n",
        "#end = time.time()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute '_jvm'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\34639\\Documents\\GitHub\\SDComputing_labs\\LAB2\\Study2.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/34639/Documents/GitHub/SDComputing_labs/LAB2/Study2.ipynb#ch0000010?line=0'>1</a>\u001b[0m \u001b[39m# Doing the heavy lifting in Spark. We could leverage the `histogram` function from the RDD api\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/34639/Documents/GitHub/SDComputing_labs/LAB2/Study2.ipynb#ch0000010?line=2'>3</a>\u001b[0m gre_histogram \u001b[39m=\u001b[39m data_sp\u001b[39m.\u001b[39;49mselect(\u001b[39m'\u001b[39;49m\u001b[39mhour\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mrdd\u001b[39m.\u001b[39mflatMap(\u001b[39mlambda\u001b[39;00m x: x)\u001b[39m.\u001b[39mhistogram(\u001b[39m11\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/34639/Documents/GitHub/SDComputing_labs/LAB2/Study2.ipynb#ch0000010?line=4'>5</a>\u001b[0m \u001b[39m# Loading the Computed Histogram into a Pandas Dataframe for plotting\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/34639/Documents/GitHub/SDComputing_labs/LAB2/Study2.ipynb#ch0000010?line=5'>6</a>\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/34639/Documents/GitHub/SDComputing_labs/LAB2/Study2.ipynb#ch0000010?line=6'>7</a>\u001b[0m     \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mgre_histogram)), \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/34639/Documents/GitHub/SDComputing_labs/LAB2/Study2.ipynb#ch0000010?line=7'>8</a>\u001b[0m     columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mbin\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfrequency\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/34639/Documents/GitHub/SDComputing_labs/LAB2/Study2.ipynb#ch0000010?line=8'>9</a>\u001b[0m )\u001b[39m.\u001b[39mset_index(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/34639/Documents/GitHub/SDComputing_labs/LAB2/Study2.ipynb#ch0000010?line=9'>10</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbin\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/34639/Documents/GitHub/SDComputing_labs/LAB2/Study2.ipynb#ch0000010?line=10'>11</a>\u001b[0m )\u001b[39m.\u001b[39mplot(kind\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbar\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\sql\\dataframe.py:1685\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/dataframe.py?line=1663'>1664</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mcols):\n\u001b[0;32m   <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/dataframe.py?line=1664'>1665</a>\u001b[0m     \u001b[39m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/dataframe.py?line=1665'>1666</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/dataframe.py?line=1666'>1667</a>\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/dataframe.py?line=1682'>1683</a>\u001b[0m \u001b[39m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/dataframe.py?line=1683'>1684</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/dataframe.py?line=1684'>1685</a>\u001b[0m     jdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jdf\u001b[39m.\u001b[39mselect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jcols(\u001b[39m*\u001b[39;49mcols))\n\u001b[0;32m   <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/dataframe.py?line=1685'>1686</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(jdf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msql_ctx)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\sql\\dataframe.py:1441\u001b[0m, in \u001b[0;36mDataFrame._jcols\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/dataframe.py?line=1438'>1439</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cols) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(cols[\u001b[39m0\u001b[39m], \u001b[39mlist\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/dataframe.py?line=1439'>1440</a>\u001b[0m     cols \u001b[39m=\u001b[39m cols[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/dataframe.py?line=1440'>1441</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jseq(cols, _to_java_column)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\sql\\dataframe.py:1428\u001b[0m, in \u001b[0;36mDataFrame._jseq\u001b[1;34m(self, cols, converter)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/dataframe.py?line=1425'>1426</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_jseq\u001b[39m(\u001b[39mself\u001b[39m, cols, converter\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/dataframe.py?line=1426'>1427</a>\u001b[0m     \u001b[39m\"\"\"Return a JVM Seq of Columns from a list of Column or names\"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/dataframe.py?line=1427'>1428</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _to_seq(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msql_ctx\u001b[39m.\u001b[39;49m_sc, cols, converter)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\sql\\column.py:61\u001b[0m, in \u001b[0;36m_to_seq\u001b[1;34m(sc, cols, converter)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=53'>54</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=54'>55</a>\u001b[0m \u001b[39mConvert a list of Column (or names) into a JVM Seq of Column.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=55'>56</a>\u001b[0m \n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=56'>57</a>\u001b[0m \u001b[39mAn optional `converter` could be used to convert items in `cols`\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=57'>58</a>\u001b[0m \u001b[39minto JVM Column objects.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=58'>59</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=59'>60</a>\u001b[0m \u001b[39mif\u001b[39;00m converter:\n\u001b[1;32m---> <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=60'>61</a>\u001b[0m     cols \u001b[39m=\u001b[39m [converter(c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m cols]\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=61'>62</a>\u001b[0m \u001b[39mreturn\u001b[39;00m sc\u001b[39m.\u001b[39m_jvm\u001b[39m.\u001b[39mPythonUtils\u001b[39m.\u001b[39mtoSeq(cols)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\sql\\column.py:61\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=53'>54</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=54'>55</a>\u001b[0m \u001b[39mConvert a list of Column (or names) into a JVM Seq of Column.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=55'>56</a>\u001b[0m \n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=56'>57</a>\u001b[0m \u001b[39mAn optional `converter` could be used to convert items in `cols`\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=57'>58</a>\u001b[0m \u001b[39minto JVM Column objects.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=58'>59</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=59'>60</a>\u001b[0m \u001b[39mif\u001b[39;00m converter:\n\u001b[1;32m---> <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=60'>61</a>\u001b[0m     cols \u001b[39m=\u001b[39m [converter(c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m cols]\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=61'>62</a>\u001b[0m \u001b[39mreturn\u001b[39;00m sc\u001b[39m.\u001b[39m_jvm\u001b[39m.\u001b[39mPythonUtils\u001b[39m.\u001b[39mtoSeq(cols)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\sql\\column.py:43\u001b[0m, in \u001b[0;36m_to_java_column\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=40'>41</a>\u001b[0m     jcol \u001b[39m=\u001b[39m col\u001b[39m.\u001b[39m_jc\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=41'>42</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(col, \u001b[39mstr\u001b[39m):\n\u001b[1;32m---> <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=42'>43</a>\u001b[0m     jcol \u001b[39m=\u001b[39m _create_column_from_name(col)\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=43'>44</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=44'>45</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=45'>46</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mInvalid argument, not a string or column: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=46'>47</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m of type \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=47'>48</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFor column literals, use \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlit\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39marray\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mstruct\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mcreate_map\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=48'>49</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfunction.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(col, \u001b[39mtype\u001b[39m(col)))\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\sql\\column.py:36\u001b[0m, in \u001b[0;36m_create_column_from_name\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=33'>34</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_column_from_name\u001b[39m(name):\n\u001b[0;32m     <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=34'>35</a>\u001b[0m     sc \u001b[39m=\u001b[39m SparkContext\u001b[39m.\u001b[39m_active_spark_context\n\u001b[1;32m---> <a href='file:///c%3A/Users/34639/AppData/Local/Packages/PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0/LocalCache/local-packages/Python310/site-packages/pyspark/sql/column.py?line=35'>36</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m sc\u001b[39m.\u001b[39;49m_jvm\u001b[39m.\u001b[39mfunctions\u001b[39m.\u001b[39mcol(name)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_jvm'"
          ]
        }
      ],
      "source": [
        "# Doing the heavy lifting in Spark. We could leverage the `histogram` function from the RDD api\n",
        "\n",
        "gre_histogram = data_sp.select('hour').rdd.flatMap(lambda x: x).histogram(11)\n",
        "\n",
        "# Loading the Computed Histogram into a Pandas Dataframe for plotting\n",
        "pd.DataFrame(\n",
        "    list(zip(*gre_histogram)), \n",
        "    columns=['bin', 'frequency']\n",
        ").set_index(\n",
        "    'bin'\n",
        ").plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "1942420\n",
            "29823363.75990732\n",
            "15.353715344728391\n",
            "0.4974637874404094\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd \n",
        "spark = SparkSession.builder.appName(\"prueba\").master(\"local[*]\").getOrCreate()\n",
        "\n",
        "#Again, we begin by reading our data. \n",
        "\n",
        "data_spark = spark.read.option(\"header\",\"true\").csv(\"tripdata_2017-01.csv\")\n",
        "\n",
        "#Now, we select the columns corresponding to the amount of money excluding the taxes. \n",
        "no_taxes = data['fare_amount'] + data['tip_amount'] + data['tolls_amount'] + data['extra'] + data['improvement_surcharge']\n",
        "\n",
        "#Since we want the redd to be created from a list, we transform this python series into a list.\n",
        "no_taxes_list = no_taxes.tolist()\n",
        "#Let's check that it is indeed a list. \n",
        "print(type(no_taxes_list))\n",
        "#Now, we create the rdd object. \n",
        "rdd=spark.sparkContext.parallelize(no_taxes_list)\n",
        "\n",
        "#Since we want to compute the mean value, we need to compute the sum of all the elements of the object, the count of these elements \n",
        "#and divide them. \n",
        "\n",
        "#Let's start by computing and printing the number of observations present in the rdd object. \n",
        "count = rdd.count()\n",
        "print(count)\n",
        "#Secondly, we sum the elements of the rdd thanks to the function .reduce(), which allows us to make computations between the elements\n",
        "#of a list. \n",
        "suma = rdd.reduce(lambda a,b : (a+b))\n",
        "print(suma)\n",
        "#Lastly, we divide them and obtain the mean value. \n",
        "print(suma/count)\n",
        "\n",
        "#We can do the same thing for the 'mta_tax' value. \n",
        "\n",
        "taxes = data['mta_tax'] \n",
        "taxes_list = taxes.tolist()\n",
        "\n",
        "rdd2 = spark.sparkContext.parallelize(taxes_list)\n",
        "count2 = rdd2.count()\n",
        "suma2 = rdd2.reduce(lambda a,b : a+b)\n",
        "\n",
        "mean = suma2/count2\n",
        "print(mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Study2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
