load("C:/Users/Alberto/Downloads/MNIST-tSNE.RData")
View(MNIST)
mnist <- as.data.frame(MNIST)
View(mnist)
library(caret)
nrow(mnist)
training <- mnist[1:50000,]
train_labels <- MNIST$labels[1:50000]
plot(training, col = rainbow(10)[train_labels +1], pch =16, cex = 0.1)
training <- mnist[1:50000,]
train_labels <- MNIST$labels[1:50000]
plot(training, col = rainbow(10)[train_labels +1], pch =16, cex = 0.1)
load("C:/Users/Alberto/Downloads/MNIST-tSNE.RData")
mnist <- as.data.frame(MNIST)
training <- mnist[1:50000,]
train_labels <- MNIST$labels[1:50000]
plot(training, col = rainbow(10)[train_labels +1], pch =16, cex = 0.1)
training <- mnist$y_tsne[1:50000,]
train_labels <- MNIST$labels[1:50000]
plot(training, col = rainbow(10)[train_labels +1], pch =16, cex = 0.1)
mnist <- as.data.frame(MNIST$x)
training <- mnist$y_tsne[1:50000,]
train_labels <- MNIST$labels[1:50000]
plot(training, col = rainbow(10)[train_labels +1], pch =16, cex = 0.1)
load("C:/Users/Alberto/Downloads/MNIST-tSNE.RData")
training <- MNIST$y_tsne[1:50000,]
train_labels <- MNIST$labels[1:50000]
plot(training, col = rainbow(10)[train_labels +1], pch =16, cex = 0.1)
legend("bottomright", legend = 0:9, col = rainbow(10), pch = 16, title = "Digits")
test <- MNIST$y_tsne[50001:60000,}]
test <- MNIST$y_tsne[50001:60000,]
test_labels <- MNIST$labels[50001:60000]
kda_1 <- ks::kda(x = x, x.group = groups)
#b) Using the training sample, compute the plug-in bandwidth matrices for all the classes.
install.packages("ks")
library(ks)
kda_1 <- ks::kda(x = x, x.group = groups)
kda_1 <- ks::kda(x = training, x.group = MNIST$labels)
hs <- ks::hkda(x = training, x.group = MNIST$labels, bw = "plugin")
hs
kda_1 <- ks::kda(x = training, x.group = MNIST$labels, hs = hs)
library(plyr)
library(dplyr)
library(factoextra)
library(magrittr)
library(ggplot2)
library(microbenchmark)
set.seed(13)
data5k=read.csv(file = "computers5k.csv",header = T)
data5k$id = NULL
data5k$cd %<>% mapvalues(from = c("yes","no"), to = c("1","0"))  %>% as.factor()
library(plyr)
setwd("C:/Users/Alberto/Desktop/Máster UC3M/3rd quarter/Computación Escalada/SDComputing_labs")
library(dplyr)
library(factoextra)
library(magrittr)
library(ggplot2)
library(microbenchmark)
set.seed(13)
data5k=read.csv(file = "computers5k.csv",header = T)
data5k$id = NULL
data5k$cd %<>% mapvalues(from = c("yes","no"), to = c("1","0"))  %>% as.factor()
data5k$laptop %<>% mapvalues(from = c("yes","no"), to = c("1","0")) %>% as.factor()
summary(data5k)
#kmeans only work with numeric vectors
data_wo_factors = data5k %>% dplyr::select(c(-cd,-laptop))
#Used to generate random numbers
generate_random=function(vector){
return(runif(1,min(vector),max(vector)))
}
euclidian=function(a,b){
sqrt(sum((a-b)^2))
}
knn_diy=function(data,k){
#Scale data
knn_data=as.data.frame(scale(data))
#Generate random centroids
X=matrix(nrow=k,ncol=ncol(knn_data)+1)
clusters=letters[1:k]
for (i in 1:nrow(X)) {
for(j in 1:ncol(knn_data)){
X[i,j]=generate_random(knn_data[,j])
}
}
X[,ncol(knn_data)+1]=as.factor(letters[1:k])
#Compute Distances
x=c()
knn_data$error=NULL
knn_data$cluster=NULL
for (i in 1:nrow(knn_data)) {
for(j in 1:nrow(X)){
x[j]=euclidian(X[j,-ncol(X)],knn_data[i,1:(ncol(knn_data)-2)])
}
knn_data$error[i]<-min(x)
knn_data$cluster[i]<-which(x==min(x))
}
#
print(head(knn_data))
#
#Check errors
error=c(0,sum(knn_data$error))
e=2
#
print(error)
#
while(round(error[e],2)!= round(error[e-1],2)){
#Compute distances
x=c()
for (i in 1:nrow(knn_data)) {
for(j in 1:nrow(X)){
x[j]=euclidian(X[j,-ncol(X)],knn_data[i,1:(ncol(knn_data)-2)])
}
knn_data$error[i]<-min(x)
knn_data$cluster[i]<-which(x==min(x))
}
#Write error
error=c(error,sum(knn_data$error))
#Recode Clusters
#knn_data$cluster %<>% as.factor()
X= knn_data %>% group_by(cluster) %>%
dplyr::summarize(price=mean(price),
speed=mean(speed),
hd=mean(hd),
ram=mean(ram),
screen=mean(screen),
cores=mean(cores),
trend=mean(trend)) %>%
mutate(n_centroide=cluster) %>%
select(-cluster) %>%
ungroup() %>% as.data.frame(.)
#Next iteration
e=e+1
#
print(error)
#
}
return(knn_data)
}
obtain_k_optimal=function(kmax){
knn=NULL
for (i in 1:kmax) {
knn[i]=list(knn_diy(data_wo_factors,i))
}
return(knn)
}
knn_data2=obtain_k_optimal(5)
x=NULL
y=NULL
for (i in 1:length(knn)) {
y[i]=sum(knn[[i]]$error)
x[i]=i
}
df=data.frame(x,y)
x=NULL
y=NULL
for (i in 1:length(knn_data2)) {
y[i]=sum(knn_data2[[i]]$error)
x[i]=i
}
df=data.frame(x,y)
ggplot(data = df, aes(x=x,y=y)) + geom_point() + geom_line()
ggplot(knn_data,aes(x=price,y=speed,color=as.factor(cluster))) + geom_point()
ggplot(knn_data2,aes(x=price,y=speed,color=as.factor(cluster))) + geom_point()
ggplot(knn_data2[[2]],aes(x=price,y=speed,color=as.factor(cluster))) + geom_point()
hpricefun <- function(datos){
x = list()
n = ncol(datos)
datos[,n] %<>% as.factor()
k = length(levels(datos[,n]))
for(i in 1:k){
ind1 <- which(knn_data$cluster==i)
price1 <- knn_data$price[ind1]
x[i]=mean(price1)
}
return(x)
}
hpricefun(knn_data2)
hpricefun <- function(datos){
x = list()
n = ncol(datos)
datos[,n] %<>% as.factor()
k = length(levels(datos[,n]))
for(i in 1:k){
ind1 <- which(knn_data2$cluster==i)
price1 <- knn_data2$price[ind1]
x[i]=mean(price1)
}
return(x)
}
hpricefun(knn_data2)
hpricefun <- function(datos){
x = list()
n = ncol(datos)
datos[,n] %<>% as.factor()
k = length(levels(datos[,n]))
for(i in 1:k){
ind1 <- which(datos$cluster==i)
price1 <- datos$price[ind1]
x[i]=mean(price1)
}
return(x)
}
hpricefun(knn_data2)
hpricefun <- function(datos){
x = list()
n = ncol(datos)
datos[,n] %<>% as.factor()
k = length(levels(datos[,n]))
for(i in 1:k){
ind1 <- which(datos$cluster==i)
price1 <- datos$price[ind1]
x[i]=mean(price1)
}
return(x)
}
hpricefun(knn_data2[[2]])
datamatrix <- data_wo_factors %<>% as.matrix()
datosknnmatrix <- knn_data2[,-c(8,9)] %<>% as.matrix()
datamatrix <- data_wo_factors %<>% as.matrix()
datosknnmatrix <- knn_data[[2]][,-c(8,9)] %<>% as.matrix()
datosknnmatrix <- knn_data2[[2]][,-c(8,9)] %<>% as.matrix()
par(mfrow = c(1, 2))
image(t(datamatrix)[, nrow(datamatrix):1], yaxt = "n", main = "Original Data")
image(t(datamatrix)[, order(knn_data$cluster)], yaxt = "n", main = "Clustered Data")
image(t(datamatrix)[, order(knn_data2$cluster)], yaxt = "n", main = "Clustered Data")
image(t(datamatrix)[, order(knn_data2[[2]]$cluster)], yaxt = "n", main = "Clustered Data")
library(plyr)
library(dplyr)
library(factoextra)
library(magrittr)
library(ggplot2)
library(microbenchmark)
library(parallel)
library(doParallel)
library(foreach)
set.seed(13)
data5k=read.csv(file = "computers5k.csv",header = T)
data5k$id = NULL
data5k$cd %<>% mapvalues(from = c("yes","no"), to = c("1","0"))  %>% as.factor()
data5k$laptop %<>% mapvalues(from = c("yes","no"), to = c("1","0")) %>% as.factor()
summary(data5k)
#kmeans only work with numeric vectors
data_wo_factors = data5k %>% dplyr::select(c(-cd,-laptop))
generate_random=function(vector){
return(runif(1,min(vector),max(vector)))
}
euclidian=function(a,b){
sqrt(sum((a-b)^2))
}
library(plyr)
library(dplyr)
library(factoextra)
library(magrittr)
library(ggplot2)
library(microbenchmark)
library(parallel)
library(doParallel)
library(foreach)
set.seed(13)
data5k=read.csv(file = "computers5k.csv",header = T)
data5k$id = NULL
data5k$cd %<>% mapvalues(from = c("yes","no"), to = c("1","0"))  %>% as.factor()
data5k$laptop %<>% mapvalues(from = c("yes","no"), to = c("1","0")) %>% as.factor()
data5k$trend %<>% as.factor()
summary(data5k)
#kmeans only work with numeric vectors
data_wo_factors = data5k %>% dplyr::select(c(-cd,-laptop,-trend))
generate_random=function(vector){
return(runif(1,min(vector),max(vector)))
}
euclidian=function(a,b){
sqrt(sum((a-b)^2))
}
knn_diy=function(data,k){
#Scale data
knn_data=as.data.frame(scale(data))
#Generate random centroids
X=matrix(nrow=k,ncol=ncol(knn_data)+1)
clusters=letters[1:k]
for (i in 1:nrow(X)) {
for(j in 1:ncol(knn_data)){
X[i,j]=generate_random(knn_data[,j])
}
}
X[,ncol(knn_data)+1]=as.factor(letters[1:k])
#Compute Distances
x=c()
knn_data$error=NULL
knn_data$cluster=NULL
for (i in 1:nrow(knn_data)) {
for(j in 1:nrow(X)){
x[j]=euclidian(X[j,-ncol(X)],knn_data[i,1:(ncol(knn_data)-2)])
}
knn_data$error[i]<-min(x)
knn_data$cluster[i]<-which(x==min(x))
}
#
print(head(knn_data))
#
#Check errors
error=c(0,sum(knn_data$error))
e=2
#
print(error)
#
while(round(error[e],2)!= round(error[e-1],2)){
#Compute distances
x=c()
for (i in 1:nrow(knn_data)) {
for(j in 1:nrow(X)){
x[j]=euclidian(X[j,-ncol(X)],knn_data[i,1:(ncol(knn_data)-2)])
}
knn_data$error[i]<-min(x)
knn_data$cluster[i]<-which(x==min(x))
}
#Write error
error=c(error,sum(knn_data$error))
#Recode Clusters
#knn_data$cluster %<>% as.factor()
X= knn_data %>% group_by(cluster) %>%
dplyr::summarize(price=mean(price),
speed=mean(speed),
hd=mean(hd),
ram=mean(ram),
screen=mean(screen),
cores=mean(cores),
trend=mean(trend)) %>%
mutate(n_centroide=cluster) %>%
select(-cluster) %>%
ungroup() %>% as.data.frame(.)
#Next iteration
e=e+1
#
print(error)
#
}
return(knn_data)
}
no_cores=detectCores()
knn_diy=function(data,k){
#Scale data
knn_data=as.data.frame(scale(data))
#Generate random centroids
X=matrix(nrow=k,ncol=ncol(knn_data)+1)
clusters=letters[1:k]
for (i in 1:nrow(X)) {
for(j in 1:ncol(knn_data)){
X[i,j]=generate_random(knn_data[,j])
}
}
X[,ncol(knn_data)+1]=as.factor(letters[1:k])
#Compute Distances
x=c()
knn_data$error=NULL
knn_data$cluster=NULL
for (i in 1:nrow(knn_data)) {
for(j in 1:nrow(X)){
x[j]=euclidian(X[j,-ncol(X)],knn_data[i,1:(ncol(knn_data)-2)])
}
knn_data$error[i]<-min(x)
knn_data$cluster[i]<-which(x==min(x))
}
#
print(head(knn_data))
#
#Check errors
error=c(0,sum(knn_data$error))
e=2
#
print(error)
#
while(round(error[e],2)!= round(error[e-1],2)){
#Compute distances
x=c()
for (i in 1:nrow(knn_data)) {
for(j in 1:nrow(X)){
x[j]=euclidian(X[j,-ncol(X)],knn_data[i,1:(ncol(knn_data)-2)])
}
knn_data$error[i]<-min(x)
knn_data$cluster[i]<-which(x==min(x))
}
#Write error
error=c(error,sum(knn_data$error))
#Recode Clusters
#knn_data$cluster %<>% as.factor()
X= knn_data %>% group_by(cluster) %>%
dplyr::summarize(price=mean(price),
speed=mean(speed),
hd=mean(hd),
ram=mean(ram),
screen=mean(screen),
cores=mean(cores)),
#trend=mean(trend)) %>%
mutate(n_centroide=cluster) %>%
select(-cluster) %>%
ungroup() %>% as.data.frame(.)
#Next iteration
e=e+1
#
print(error)
#
}
return(knn_data)
}
knn_diy=function(data,k){
#Scale data
knn_data=as.data.frame(scale(data))
#Generate random centroids
X=matrix(nrow=k,ncol=ncol(knn_data)+1)
clusters=letters[1:k]
for (i in 1:nrow(X)) {
for(j in 1:ncol(knn_data)){
X[i,j]=generate_random(knn_data[,j])
}
}
X[,ncol(knn_data)+1]=as.factor(letters[1:k])
#Compute Distances
x=c()
knn_data$error=NULL
knn_data$cluster=NULL
for (i in 1:nrow(knn_data)) {
for(j in 1:nrow(X)){
x[j]=euclidian(X[j,-ncol(X)],knn_data[i,1:(ncol(knn_data)-2)])
}
knn_data$error[i]<-min(x)
knn_data$cluster[i]<-which(x==min(x))
}
#
print(head(knn_data))
#
#Check errors
error=c(0,sum(knn_data$error))
e=2
#
print(error)
#
while(round(error[e],2)!= round(error[e-1],2)){
#Compute distances
x=c()
for (i in 1:nrow(knn_data)) {
for(j in 1:nrow(X)){
x[j]=euclidian(X[j,-ncol(X)],knn_data[i,1:(ncol(knn_data)-2)])
}
knn_data$error[i]<-min(x)
knn_data$cluster[i]<-which(x==min(x))
}
#Write error
error=c(error,sum(knn_data$error))
#Recode Clusters
#knn_data$cluster %<>% as.factor()
X= knn_data %>% group_by(cluster) %>%
dplyr::summarize(price=mean(price),
speed=mean(speed),
hd=mean(hd),
ram=mean(ram),
screen=mean(screen),
cores=mean(cores)) %>%
mutate(n_centroide=cluster) %>%
select(-cluster) %>%
ungroup() %>% as.data.frame(.)
#Next iteration
e=e+1
#
print(error)
#
}
return(knn_data)
}
no_cores=detectCores()
clust=makeCluster(no_cores,type = "FORK")
